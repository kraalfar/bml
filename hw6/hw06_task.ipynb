{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рекуррентные сети пишут тексты\n",
    "__Суммарное количество баллов: 12__\n",
    "\n",
    "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
    "\n",
    "__Тема письма: `[ML][MS][HW06] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
    "\n",
    "В этом задании вам предстоит познакомиться с объединением Deep Learning и NLP. Для начала предстоит построить векторное пространство для словоря, а затем применить его для предсказания следующих слов в тексте."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "from collections import defaultdict\n",
    "from torch.autograd import Variable\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = json.load(open(\"opencorp.json\", \"r\", encoding=\"UTF-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (3 балла)\n",
    "Чтобы обучить нейронную сеть, нам нужен датасет. В данном задании предлагается использовать данные, полученные из корпуса текстов OpenCorpora. Более того, датасет нужно представить в удобном виде. Поскольку мы хотим обучать эмбеддинги на парах `(token_center, token_context)`, а также иметь возможность делать `negative sampling`, датасет должен уметь выдавать соответствующие пары, а так же `negative sampling`-токены. \n",
    "\n",
    "Кроме того, мы бы не хотели строить эмбеддинги для очень редких слов, поэтому в словарь и в пары должны входить только слова, которые встречаются более `count_threshold` раз, а остальные должны быть заменены на специальный токен `\"<UNKNOWN>\"`. Последовательность должна начинаться с токена `\"<START>\"` и заканчиваться токеном `\"<END>\"`.\n",
    "\n",
    "#### Методы\n",
    "`__init__` - принимает на вход список последовтельностей токенов, преобразуя в соответствии с описанными выше критериями. При инициализации списка токенов нужно учитывать, что с вероятностью $1 - (\\sqrt{\\frac{0.001}{f(t)}} + 1) \\cdot \\frac{f(t)}{0.001}$ ($f(t)$ - частота слова в корпусе) мы \"выкидываем\" слово из текста, не добавляя никакие пары токенов с его участием в список. Это нужно для того, чтобы мы не переобучались на часто встречаемые слова. Также в `self.voc` должен записать актуальный словарь токенов.\n",
    "\n",
    "`__len__` - возвращает количество пар `(token_center, token_context)`\n",
    "\n",
    "`__getitem__` - принимает на вход индекс `i`, соответствующий паре `(t_i, c_i)`. Возвращает пару тензоров `(t_i, [c_i] + negatives)`, где `negatives` - список негативных токенов.\n",
    "\n",
    "`negative_sampling` - осуществляет взвешенное негативное сэмплирование. Вес токена определяется как $\\frac{(count(t))^{0.75}}{\\sum (count(t))^{0.75}}$, т.е. в negative samples частые слова попадают чаще, чем другие."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenDataset(Dataset):\n",
    "    def __init__(self, tokenized_sources, window=3, count_threshold=5, negative_sampling=5):\n",
    "        self.token_pairs = []\n",
    "        self.neg_samp = negative_sampling\n",
    "        self.counts = {\"<START>\": len(tokenized_sources), \"<END>\": len(tokenized_sources), \"<UNKNOWN>\":0}\n",
    "        \n",
    "        total_words_count = 0\n",
    "        for sent in tokenized_sources:\n",
    "            total_words_count += len(sent)\n",
    "            for word in sent:\n",
    "                if word in self.counts:\n",
    "                    self.counts[word] += 1\n",
    "                else:\n",
    "                    self.counts[word] = 1\n",
    "        \n",
    "        rem_words = []\n",
    "        for word in self.counts:\n",
    "            if self.counts[word] < count_threshold:\n",
    "                if word not in [\"<UNKNOWN>\", \"<START>\", \"<END>\"]:\n",
    "                    self.counts[\"<UNKNOWN>\"] += self.counts[word]\n",
    "                    rem_words.append(word)\n",
    "        [self.counts.pop(word) for word in rem_words]\n",
    "\n",
    "        to_rem = copy.deepcopy(tokenized_sources)\n",
    "        for sent in to_rem:\n",
    "            for i  in range(len(sent)):\n",
    "                if sent[i] in self.counts:\n",
    "                    word = sent[i]\n",
    "                else:\n",
    "                    word = \"<UNKNOWN>\"\n",
    "\n",
    "                if word not in [\"<START>\", \"<END>\"]:\n",
    "                    f = self.counts[word] / total_words_count * 1000\n",
    "                    f = 1 / f\n",
    "                    if np.random.rand() < 1 - np.sqrt(f) - f:\n",
    "                        sent[i] = \"<DELETED>\"\n",
    "        \n",
    "        for sent in tokenized_sources:\n",
    "            ns = [\"<START>\"] + sent + [\"<END>\"]\n",
    "            for i, word in enumerate(ns):\n",
    "                if word in self.counts:\n",
    "                    word_to_add = word\n",
    "\n",
    "                    if word == \"<DELETED>\":\n",
    "                        continue\n",
    "\n",
    "                    if word not in self.counts:\n",
    "                        word_to_add = \"<UNKNOWN>\"\n",
    "\n",
    "                    for j in range(-window, window+1):\n",
    "                        pos = i + j\n",
    "                        if pos >= 0 and pos < len(ns) and ns[pos] in self.counts and pos != i and ns[pos] != \"<DELETED>\":\n",
    "                            if self.counts[ns[pos]] < count_threshold:\n",
    "                                self.token_pairs.append((word_to_add, \"<UNKNOWN>\"))\n",
    "                            else:\n",
    "                                self.token_pairs.append((word_to_add, ns[pos]))\n",
    "            \n",
    "        \n",
    "\n",
    "        self.voc = np.array(list(self.counts.keys()))\n",
    "        self.token2id = dict([(token, i) for i, token in enumerate(self.voc)])\n",
    "                    \n",
    "    def negative_sampling(self):\n",
    "        den = 0\n",
    "        for word in self.counts:\n",
    "            den += pow(self.counts[word], 0.75)\n",
    "        ind = np.random.choice(range(len(self.counts)), \n",
    "                               p=[pow(self.counts[word], 0.75) / den for word in self.voc], \n",
    "                               size=self.neg_samp, \n",
    "                               replace=False)\n",
    "        return self.voc[ind]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        ns = [self.token2id[i] for i in self.negative_sampling()];\n",
    "        t, c = self.token_pairs[index]\n",
    "        if t not in self.voc:\n",
    "            t = \"<UNKNOWN>\"\n",
    "        if c not in self.voc:\n",
    "            c = \"<UNKNOWN>\"\n",
    "        \n",
    "        t = self.token2id[t]\n",
    "        c = self.token2id[c]\n",
    "        \n",
    "\n",
    "        return torch.tensor([t]), torch.tensor([c] + ns, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.token_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 (4 балла)\n",
    "Теперь реализуем непосредственно SkipGram. Для этого нам потребуются `torch.autograd.Variables` чтобы сделать эмбеддинги обучаемыми. Также сразу реализуем интерфейс, которым будем пользоваться для применения эмбеддингов в следующих задачах.\n",
    "\n",
    "#### Методы SkipGram\n",
    "`__init__` - принимает на вход словарь и размерность пространств эмбеддингов. Инициализирует эмбеддинги для центрального и контекстного слов.\n",
    "\n",
    "`get_variables` - возвращает лист из всех `torch.autograd.Variables`. Необходимо, чтобы инициализировать оптимизатор.\n",
    "\n",
    "`predict_proba(center_tokens, context_tokens)` - принимает на вход список центральных токенов и список списков токенов из предполагаемого контекста. Для каждого центрального токена и соответствующего ему списка контекстных токенов должен вернуть скалярное произведение центрального и контекстуального эмбеддингов.\n",
    "\n",
    "#### Методы Embedding\n",
    "`__init__` - принимает на вход обученный SkipGram\n",
    "\n",
    "`embed` - возвращает эмбеддинги для всех элементов списка\n",
    "\n",
    "`reconstruct` - для всех элементов списка возвращает наиболее подходящий токен. Не возвращает `\"<UNKNOWN>\"`\n",
    "\n",
    "`n_closest` - возвращает `n` ближайших токенов для каждого элемента списка. Не возвращает `\"<UNKNOWN>\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipGram:\n",
    "    def __init__(self, voc, latent_size):\n",
    "        self.id2token = list(voc)\n",
    "        self.token2id = dict([(token, i) for i, token in enumerate(self.id2token)])\n",
    "        self.v = Variable(torch.randn(len(voc) ,latent_size).float(), requires_grad=True)\n",
    "        self.u = Variable(torch.randn(latent_size, len(voc)).float(), requires_grad=True)\n",
    "        self.ls = latent_size\n",
    "        \n",
    "    def get_variables(self):\n",
    "        return [self.v, self.u]\n",
    "    \n",
    "    def predict_proba(self, center_ids, context_ids):\n",
    "        res = torch.zeros(len(center_ids), len(context_ids[0])).cuda()\n",
    "        for i, cid in enumerate(center_ids):\n",
    "            res[i] = torch.matmul(self.v[cid], self.u[:,context_ids[i]])\n",
    "        return res\n",
    "            \n",
    "class Embedding:\n",
    "    def __init__(self, skip_gram):\n",
    "        self.skip_gram = skip_gram\n",
    "        self.tree = KDTree(skip_gram.v.cpu().detach().numpy())\n",
    "    \n",
    "    def embed(self, tokens):\n",
    "        res = torch.zeros(len(tokens) , self.skip_gram.ls)\n",
    "        for i, token in enumerate(tokens):\n",
    "            if token in self.skip_gram.token2id:\n",
    "                res[i] = self.skip_gram.v[self.skip_gram.token2id[token]]\n",
    "            else:\n",
    "                res[i] = self.skip_gram.v[self.skip_gram.token2id[\"<UNKNOWN>\"]]\n",
    "        return res.detach().numpy()\n",
    "    \n",
    "    def reconstruct(self, embeddings):\n",
    "        _, inds = self.tree.query(embeddings, 2)\n",
    "        res = []\n",
    "        for ind in inds:\n",
    "            if not self.skip_gram.id2token[ind[0]] == \"<UNKNOWN>\":\n",
    "                res.append(self.skip_gram.id2token[ind[0]])\n",
    "            else:\n",
    "                res.append(self.skip_gram.id2token[ind[1]])\n",
    "        return res\n",
    "\n",
    "    def n_closest(self, embeddings, n=5):\n",
    "        res = [[] for _ in range(len(embeddings))]\n",
    "        _, inds = self.tree.query(embeddings, k=n+1)\n",
    "        for i, _ in enumerate(embeddings):\n",
    "            for ind in inds[i]:\n",
    "                if self.skip_gram.id2token[ind] != \"<UNKNOWN>\" and len(res[i]) < n:\n",
    "                    res[i].append(self.skip_gram.id2token[ind])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1192.802734375"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset) / 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "skipgram = SkipGram(dataset.voc, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating dataset...\n",
      "Creating skipgram...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d661ed6ca1714d9699c7498cc2f44eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1193), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 3.664204770341603\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c298e5d3154c04a0e0cd7c24576951",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1193), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-91a229751549>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mavg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0msteps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mskipgram\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tqdm\\notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m                 \u001b[1;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1079\u001b[0m             \"\"\"), fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[0;32m   1080\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1081\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m             \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    343\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    383\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-7e17151d2844>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnegative_sampling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m         \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoken_pairs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-7e17151d2844>\u001b[0m in \u001b[0;36mnegative_sampling\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mden\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         ind = np.random.choice(range(len(self.counts)), \n\u001b[1;32m---> 68\u001b[1;33m                                \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mden\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m                                \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneg_samp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                                replace=False)\n",
      "\u001b[1;32m<ipython-input-4-7e17151d2844>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[0mden\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         ind = np.random.choice(range(len(self.counts)), \n\u001b[1;32m---> 68\u001b[1;33m                                \u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcounts\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.75\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mden\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m                                \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneg_samp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m                                replace=False)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 4096\n",
    "EPOCHS = 2\n",
    "\n",
    "print(\"Creating dataset...\")\n",
    "dataset = TokenDataset(tokenized, count_threshold=20, window=2, negative_sampling=4)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "print(\"Creating skipgram...\")\n",
    "skipgram = SkipGram(dataset.voc, 20)\n",
    "optim = torch.optim.Adam(skipgram.get_variables(), lr=1e-3)\n",
    "y = torch.tensor([0] * (BATCH_SIZE + 1), dtype=torch.long).cuda()\n",
    "losses = []\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    avg_loss = 0\n",
    "    steps = 0\n",
    "    for batch in tqdm(dataloader):\n",
    "        probs = skipgram.predict_proba(batch[0], batch[1])\n",
    "        loss = F.cross_entropy(probs, y[:len(probs)])\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        avg_loss += loss.item()\n",
    "        steps += 1\n",
    "    losses.append(avg_loss/steps)\n",
    "    print(\"Loss:\", avg_loss/steps)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(list(range(EPOCHS)), losses)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В коде обучения все работает быстро кроме итерирования по tqdm(dataloader). Все время из-за этого и становится таким большим. Время на просто __getitem__ от __BATCH_SIZE__ элементов датасета такого же порядка, поэтому не понятно как улучшить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = Embedding(skipgram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['король', 'октябре', 'комиссия', 'самое', 'существ', 'виду', 'федеральными', 'второе', 'египте', 'придумали']\n",
      "['благодаря', 'судебные', 'паспорт', 'значительные', 'посмотрели', 'про', 'частью', 'функцией', 'отдельно', 'проповеди']\n",
      "['благодаря', 'судебные', 'паспорт', 'значительные', 'посмотрели', 'про', 'частью', 'функцией', 'отдельно', 'проповеди']\n",
      "['дать', 'пол', 'возраст', 'половиной', 'сделать', 'во', 'отсутствует', 'законе', 'проблемы', 'для']\n",
      "['ты', 'способ', 'развивается', 'сидит', 'у', 'краю', 'суде', 'российской', 'ещё', 'кто']\n",
      "['я', 'могут', 'имеют', 'силы', 'оснований', 'сделаны', '(', 'так', 'является', 'образуют']\n"
     ]
    }
   ],
   "source": [
    "king = embedder.embed([\"король\"])[0]\n",
    "cat = embedder.embed([\"кошка\"])[0]\n",
    "owl = embedder.embed([\"сыч\"])[0]\n",
    "give = embedder.embed([\"дать\"])[0]\n",
    "me = embedder.embed([\"ты\"])[0]\n",
    "you = embedder.embed([\"я\"])[0]\n",
    "print(embedder.n_closest([king], 10)[0])\n",
    "print(embedder.n_closest([cat], 10)[0])\n",
    "print(embedder.n_closest([owl], 10)[0])\n",
    "print(embedder.n_closest([give], 10)[0])\n",
    "print(embedder.n_closest([me], 10)[0])\n",
    "print(embedder.n_closest([you], 10)[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3 (2 балла)\n",
    "Теперь будем учиться восстанавливать слова в тексте. Для этого нам потребуется также определить датасет последовательностей фиксированной длинны.\n",
    "\n",
    "#### Методы\n",
    "`__init__` - принимает на вход `embedder` (обученный SkipGram) и список токенизированных последоватлеьностей `tokenized`.\n",
    "\n",
    "`__getitem__` - возвращает случайную закодированную при помощи SkipGram подпоследовательность длины `seq_len` одной из исходных последовательностей, сдвинутую на один токен подпоследовательность (т.е. следующие слова в тексте) и маску, которая отражает то, является ли токен неизвестным (`\"<UNKNOWN\"`).\n",
    "\n",
    "`__len__` - равна количеству последовательностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenSeqDataset(Dataset):\n",
    "    def __init__(self, embedder, tokenized, seq_len=32):\n",
    "        self.seq_len = seq_len\n",
    "        self.tokenized = tokenized\n",
    "        self.embedder = embedder\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(tokenized)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        top = max(len(self.tokenized[index]) - self.seq_len, 0)\n",
    "\n",
    "        ind = np.random.randint(0, 1 + top)\n",
    "\n",
    "        sent = copy.deepcopy(self.tokenized[index])\n",
    "        sent = sent + [\"<END>\"] * (1 + max(0, self.seq_len-len(sent)))\n",
    "        seq = sent[ind: ind + self.seq_len + 1]\n",
    "        mask = [token in self.embedder.skip_gram.token2id for token in seq[1:]]\n",
    "        mask = torch.Tensor(np.array(mask))\n",
    "        resseq = [self.embedder.embed([word])[0] for word in seq]\n",
    "        resseq = torch.Tensor(np.array(resseq))\n",
    "        a1 = copy.deepcopy(resseq[:-1])\n",
    "        a2 = copy.deepcopy(resseq[1:])\n",
    "        return a1, a2, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4 (2 балла)\n",
    "Теперь обучим рекуррентную сеть, которая будет предсказывать следующее слово в тексте. Модель будет состоять из трех блоков: `input` (отвечает за предоброботку эмбеддинга), `rnn` (рекуррентная часть), `output` (отвечает за постобработку выхода).\n",
    "\n",
    "#### Методы\n",
    "`predict_sequential` - возвращает последовательность предсказаний для батча последовательностей\n",
    "\n",
    "`get_next` - предсказывает следующее слово\n",
    "\n",
    "`reset` - обнуляет внутреннее состояние сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRNN:\n",
    "    def __init__(self, latent_space=150, hidden_layer=512):\n",
    "        self.input = torch.nn.Sequential(\n",
    "            torch.nn.Linear(latent_space, hidden_layer),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_layer, hidden_layer),\n",
    "            torch.nn.ReLU()\n",
    "        )\n",
    "        self.rnn = torch.nn.LSTM(hidden_layer, hidden_layer)\n",
    "        self.output = torch.nn.Linear(hidden_layer, latent_space)\n",
    "        self.input.cuda()\n",
    "        self.rnn.cuda()\n",
    "        self.output.cuda()\n",
    "        self.hidden = None\n",
    "    \n",
    "    def predict_sequential(self, sequences):\n",
    "        x, _ = self.rnn(self.input(sequences))\n",
    "        return self.output(x)\n",
    "    \n",
    "    def parameters(self):\n",
    "        return list(self.input.parameters()) + list(self.rnn.parameters()) + list(self.output.parameters())\n",
    "    \n",
    "    def get_next(self, batch):\n",
    "        x, self.hidden = self.rnn(self.input(batch).unsqueeze(1))\n",
    "        return self.output(x)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.hidden = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b3683189f94b1898fa9cbdcc2eaf46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.26283620065232843\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2f4964270449d791618c5a0d9c1991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.26055325644455873\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ab954209e448859c5d1895a6a4e479",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25954786173231975\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b088d8e870ce487da4adbb81e501164f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2587518052900352\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d6e0d9f48b4c57a3c8473c6a7c4dea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25829236021271573\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c8ba26ef0c4e5f8c77d458e538453d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25754150562607175\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d6328352f244fa8f1678aabbcec97c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2569683868425629\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66321d4c3e654bbeaf59eb724513e6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2563957179157045\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ae8566ff1de4b428feee080d7c479de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2560213052751218\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88a694a740449c3af0c512dbece23f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25577617142089576\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ca1d18981e84a13af6141eceac38d39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2555515126780022\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f635cd41e4474d8d761e09382a1932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25503796148438784\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad55dc9e3bf4d7ba8fd9e01e0aca340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25492746974542685\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc68c52387b3408e9232a5c492a69597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2544229314028227\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6571e750d30140b98a5be47bfb3106f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2544488636065163\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdd340f2ab0844828b41be32532e2c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2540959543316467\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "549e5cb9a043442f960d60cc941ed316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25451399160678995\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "219deeeb65c9496481a23be43311aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2542870692240439\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a16af1b21414a22affb0390f43ba602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.254150217330931\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce42374fea34973bbaa57fae6242538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2538393207166678\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73c5f0dc1ee49e3b10b0f6e5f947123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25389482922530254\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdadbfb74aa24f3a813b9fa7cf36abcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2536973187149165\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242794a00d3d46e78a018ef30443e2f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2539374561998931\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcea99c88596474a826c51bfc0dec076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25380741723154077\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0376edcea554315b0d98ebbb255adf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2537076031894383\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75215df85a904b0b86b5913d06729a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25368664591910434\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ffac3f995ab466a8e7baa1ad40271c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2537927950834515\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c40d75af4254368bcf8115b3fcfcc41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2535001198170193\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e31f283e45949eaa8b0f9482fdfde75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2534502568187508\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44d684b77454776840ffd4d7002c9e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25347533594334243\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4624cd4c689b42e2aa98fff0524e9b93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25347833983921925\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598faa1430ed4b3889557b4edaba8724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2534227202649528\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e74409820da5497597f67ed612939c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2532330115273149\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f716733f61eb4c38a254e33009555f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25319774349860574\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1da786d160248549e4c51b4464338c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2532624540188384\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4ddf6b7f67d4228b0cbae6d5e68101a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2532740538549978\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e98f727cdc51490c91bc7b59b6fe7e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2531084873995116\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd8d83a2a97a450f854d3e959a5397cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.253155072191823\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ca05ca4abb40b5ab60ac711c7d29f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2530775073655816\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30472dad66e94fef9793e39cf1a527d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25326297781198126\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256d11a71b1c439fa922cf1725451224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25334810336859914\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6009cbd1e86049078378281b0342230c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25330261017297984\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6b4b35e2b564954b48766287fb2d66c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25307791056328044\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b3f3c55acb84ce89f5224d180860948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25304662000598305\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16cada78cdda49b68f68bffeb7677634",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2531220923577036\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e2aa199b32e43c19f2be17ddd16c3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2531456059692706\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be97e9049ec4855ab8921d53bd31c2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.25302413487157155\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d14e37647d41358bf0af99b6c3224b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss: 0.2529807029372434\n",
      "Top-1 accuracy: 0.0\n",
      "Top-5 accuracy: 0.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ede008c4464457b0da67edc705d4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 200\n",
    "\n",
    "dataset = TokenSeqDataset(embedder, tokenized)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "rnn = TextRNN(20)\n",
    "optim = torch.optim.Adam(rnn.parameters(), lr=1e-3)\n",
    "losses = []\n",
    "top1accs = []\n",
    "top5accs = []\n",
    "for i in range(EPOCHS):\n",
    "    avg_loss = 0\n",
    "    top1acc = 0\n",
    "    top5acc = 0\n",
    "    steps = 0\n",
    "    acc_steps = 0\n",
    "    for x, y_true, loss_mask in tqdm(dataloader):\n",
    "        y_pred = rnn.predict_sequential(x.cuda())\n",
    "        loss = (((y_true.cuda() - y_pred)**2).mean(dim=-1) * loss_mask.cuda()).mean()\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        avg_loss += loss.item()\n",
    "        steps += 1\n",
    "        if steps % 100 == 0:\n",
    "            acc_steps += 1\n",
    "            word_pred = embedder.n_closest(y_pred.detach().view(-1, 20)[:200].cpu().numpy())\n",
    "            word_true = embedder.reconstruct(y_true.detach().view(-1, 20)[:200].cpu().numpy())\n",
    "            unknown_mask = loss_mask.view(-1).cpu().numpy()\n",
    "            t1a = 0\n",
    "            t5a = 0\n",
    "            for true, pred, is_unknown in zip(word_true, word_pred, unknown_mask):\n",
    "                if is_unknown:\n",
    "                    continue\n",
    "                if true == pred[0]:\n",
    "                    t1a += 1\n",
    "                if true in pred:\n",
    "                    t5a += 1\n",
    "            top1acc += t1a / len(word_pred)\n",
    "            top5acc += t5a / len(word_pred)\n",
    "    losses.append(avg_loss/steps)\n",
    "    top1accs.append(top1acc/acc_steps)\n",
    "    top5accs.append(top5acc/acc_steps)\n",
    "    print(\"Loss:\", avg_loss/steps)\n",
    "    print(\"Top-1 accuracy:\", top1acc/acc_steps)\n",
    "    print(\"Top-5 accuracy:\", top5acc/acc_steps)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(list(range(EPOCHS)), losses)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(list(range(100)), top1accs, label=\"Top-1\")\n",
    "plt.plot(list(range(100)), top5accs, label=\"Top-5\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "is_unknown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5 (1 балл)\n",
    "Отлично, осталось только научитсья итеративно продолжать последовательность. Давайте попробуем научиться это делать.\n",
    "\n",
    "#### Методы\n",
    "`continue_sequence` - возвращает завершенную последовательность. Входная последовательность может быть пустой, поэтому в начало нужно добавить токен `\"<START>\"`. Закончить построение последовательности нужно после получения токена `\"<END>\"` или после получения `max_len` новых слов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceCompleter:\n",
    "    def __init__(self, rnn, embedder, max_len=128):\n",
    "        self.rnn = rnn\n",
    "        self.embedder = embedder\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def continue_sequence(self, sequence):\n",
    "        t_sequence = [\"<START>\"] + sequence\n",
    "        embedding = self.embedder.embed(t_sequence)\n",
    "        self.rnn.reset()\n",
    "        with torch.no_grad():\n",
    "            for e in embedding:\n",
    "                x = self.rnn.get_next(torch.tensor([e], dtype=torch.float).cuda())\n",
    "            rec = self.embeder.reconstruct(x)\n",
    "            continued_sequence = []\n",
    "            ctn = 0\n",
    "            while rec[0] != \"<END>\" and ctn < self.max_len:\n",
    "                continued_sequence.append(rec[0])\n",
    "                e = self.embedder.embed(rec)\n",
    "                x = self.rnn.get_next(torch.tensor(e, dtype=torch.float).cuda())\n",
    "                rec = self.embeder.reconstruct(x)\n",
    "        return sequence + continued_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3d18bbfc7361>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mseq_completer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequenceCompleter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0membedder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_completer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinue_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"учеба\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"в\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"магистратуре\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"это\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_completer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinue_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"работает\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ли\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"наша\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"простая\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"модель\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"?\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_completer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinue_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"я\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"точно\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"знаю\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_completer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontinue_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"машина\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"времени\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-5a01d5dc934f>\u001b[0m in \u001b[0;36mcontinue_sequence\u001b[1;34m(self, sequence)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0membedding\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mrec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreconstruct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mcontinued_sequence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-e24ca463e813>\u001b[0m in \u001b[0;36mget_next\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sequences' is not defined"
     ]
    }
   ],
   "source": [
    "seq_completer = SequenceCompleter(rnn, embedder)\n",
    "print(seq_completer.continue_sequence([\"учеба\", \"в\", \"магистратуре\", \"-\", \"это\"]))\n",
    "print(seq_completer.continue_sequence([\"работает\", \"ли\", \"наша\", \"простая\", \"модель\", \"?\"]))\n",
    "print(seq_completer.continue_sequence([\"я\", \"точно\", \"знаю\"]))\n",
    "print(seq_completer.continue_sequence([\"машина\", \"времени\"]))\n",
    "print(seq_completer.continue_sequence([\"сегодня\"]))\n",
    "print(seq_completer.continue_sequence([]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLSTM:\n",
    "    def __init__(self, symbols):\n",
    "        self.hidden = None\n",
    "        self.input = torch.nn.Linear(len(symbols), 128)\n",
    "        self.lstm = torch.nn.LSTM(128, 128)\n",
    "        self.output = torch.nn.Sequential(torch.nn.Linear(128, 128), torch.nn.ReLU(), torch.nn.Linear(128, len(symbols)))\n",
    "    \n",
    "    def loss(self, batch):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
