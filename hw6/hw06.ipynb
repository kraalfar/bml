{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "hw06_task.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6bb1eb39337f4bcb8273c9f216478779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1e9eb29d94214e259d81b9a7245dcb7c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_86162b5b868b4e54a302a2cc71579e45",
              "IPY_MODEL_edb31cf9073840979c28c5c94a656d4d"
            ]
          }
        },
        "fce62924c8ea4dd8a123465997f405fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9df5ebdb3de046558f04d986ad119763",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0876ce15e19c42cf8b7812c7ef52e25f",
              "IPY_MODEL_3ebaec93619e4630a095d0e50f9cea88"
            ]
          }
        },
        "60d686902fbe48faa4847c9667df3f56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7d087efa35a44edf8fecfe6f1b7a3e31",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3f9d9624ebd8465abb82cf59c895b745",
              "IPY_MODEL_5e8b1f60b1624e48bd340fb146763ef0"
            ]
          }
        },
        "ce886172b417486b85341dd11bd857e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85947c213da54060965f3e75dbe27b72",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f822ba6f6cc0456ebef167e60d077d02",
              "IPY_MODEL_0d2beec0f19945388da4cb6b3d6fcc79"
            ]
          }
        },
        "941f201d8b87486199295fed5f115a0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d1e3e0c1390847219bbf2d4f1ee1e762",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c6f83bdafd77423c98572c880234bc79",
              "IPY_MODEL_0abfa4869c354ed5874308241caddd63"
            ]
          }
        },
        "f6ef33a474024f79b4c7b8c0f4ea50e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_85657abbf8704cea9599bfe80cda9d7f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_358173710649496ca2080e3f00f99db4",
              "IPY_MODEL_4d6711507ada42adbfb054c55f03ecf7"
            ]
          }
        },
        "39ad97bdc53d4406a7af801f33d11869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0bd053cec6a84095b33d04bf790aa4e7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e52e404d1b54bbbaaa5bcd398d32466",
              "IPY_MODEL_839c34554a324928b7cd338d1dc574dd"
            ]
          }
        },
        "d8762bc4271c47b08fc499e4d47aaa53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c8428ddca95f432f898f6aab42d3e10a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fddb1915d3f940f794f5d401e30905b5",
              "IPY_MODEL_f6020f097f6647fd8833401101bdafaa"
            ]
          }
        },
        "cf713dcfb8774e5b86f000c36412b0cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4da9efed74ac49e380256f0aa3484e9f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a765d88341ec4718b2c17592b0bbda7b",
              "IPY_MODEL_3087b28c4e0741be82e7619c4287c7fe"
            ]
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4aQieT8tfHI",
        "colab_type": "text"
      },
      "source": [
        "# Рекуррентные сети пишут тексты\n",
        "__Суммарное количество баллов: 12__\n",
        "\n",
        "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
        "\n",
        "__Тема письма: `[ML][MS][HW06] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
        "\n",
        "В этом задании вам предстоит познакомиться с объединением Deep Learning и NLP. Для начала предстоит построить векторное пространство для словоря, а затем применить его для предсказания следующих слов в тексте."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxUMuDyutfHL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from sklearn.neighbors import KDTree\n",
        "import time\n",
        "from collections import defaultdict\n",
        "from torch.autograd import Variable\n",
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnM3dM3WtfHR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized = json.load(open(\"opencorp.json\", \"r\", encoding=\"UTF-8\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-IiPgPa_tfHZ",
        "colab_type": "text"
      },
      "source": [
        "### Задание 1 (3 балла)\n",
        "Чтобы обучить нейронную сеть, нам нужен датасет. В данном задании предлагается использовать данные, полученные из корпуса текстов OpenCorpora. Более того, датасет нужно представить в удобном виде. Поскольку мы хотим обучать эмбеддинги на парах `(token_center, token_context)`, а также иметь возможность делать `negative sampling`, датасет должен уметь выдавать соответствующие пары, а так же `negative sampling`-токены. \n",
        "\n",
        "Кроме того, мы бы не хотели строить эмбеддинги для очень редких слов, поэтому в словарь и в пары должны входить только слова, которые встречаются более `count_threshold` раз, а остальные должны быть заменены на специальный токен `\"<UNKNOWN>\"`. Последовательность должна начинаться с токена `\"<START>\"` и заканчиваться токеном `\"<END>\"`.\n",
        "\n",
        "#### Методы\n",
        "`__init__` - принимает на вход список последовтельностей токенов, преобразуя в соответствии с описанными выше критериями. При инициализации списка токенов нужно учитывать, что с вероятностью $1 - (\\sqrt{\\frac{0.001}{f(t)}} + 1) \\cdot \\frac{f(t)}{0.001}$ ($f(t)$ - частота слова в корпусе) мы \"выкидываем\" слово из текста, не добавляя никакие пары токенов с его участием в список. Это нужно для того, чтобы мы не переобучались на часто встречаемые слова. Также в `self.voc` должен записать актуальный словарь токенов.\n",
        "\n",
        "`__len__` - возвращает количество пар `(token_center, token_context)`\n",
        "\n",
        "`__getitem__` - принимает на вход индекс `i`, соответствующий паре `(t_i, c_i)`. Возвращает пару тензоров `(t_i, [c_i] + negatives)`, где `negatives` - список негативных токенов.\n",
        "\n",
        "`negative_sampling` - осуществляет взвешенное негативное сэмплирование. Вес токена определяется как $\\frac{(count(t))^{0.75}}{\\sum (count(t))^{0.75}}$, т.е. в negative samples частые слова попадают чаще, чем другие."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3L2E9qhtfHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TokenDataset(Dataset):\n",
        "    def __init__(self, tokenized_sources, window=3, count_threshold=5, negative_sampling=5):\n",
        "        self.token_pairs = []\n",
        "        self.neg_samp = negative_sampling\n",
        "        self.counts = {\"<START>\": len(tokenized_sources), \"<END>\": len(tokenized_sources), \"<UNKNOWN>\":0}\n",
        "        \n",
        "        total_words_count = 2 * len(tokenized_sources)\n",
        "        for sent in tokenized_sources:\n",
        "            total_words_count += len(sent)\n",
        "            for word in sent:\n",
        "                if word in self.counts:\n",
        "                    self.counts[word] += 1\n",
        "                else:\n",
        "                    self.counts[word] = 1\n",
        "        \n",
        "        rem_words = []\n",
        "        for word in self.counts:\n",
        "            if self.counts[word] < count_threshold:\n",
        "                if word not in [\"<UNKNOWN>\", \"<START>\", \"<END>\"]:\n",
        "                    self.counts[\"<UNKNOWN>\"] += self.counts[word]\n",
        "                    rem_words.append(word)\n",
        "        [self.counts.pop(word) for word in rem_words]\n",
        "\n",
        "        to_rem = copy.deepcopy(tokenized_sources)\n",
        "        for sent in to_rem:\n",
        "            for i  in range(len(sent)):\n",
        "                if sent[i] in self.counts:\n",
        "                    word = sent[i]\n",
        "                else:\n",
        "                    word = \"<UNKNOWN>\"\n",
        "                    sent[i] = \"<UNKNOWN>\"\n",
        "\n",
        "                if word not in [\"<START>\", \"<END>\"]:\n",
        "                    f = self.counts[word] / total_words_count * 1000\n",
        "                    f = 1 / f\n",
        "                    if np.random.rand() < 1 - np.sqrt(f) - f:\n",
        "                        sent[i] = \"<DELETED>\"\n",
        "        \n",
        "        for sent in to_rem:\n",
        "            ns = [\"<START>\"] + sent + [\"<END>\"]\n",
        "            for i, word in enumerate(ns):\n",
        "                if word in self.counts:\n",
        "                    word_to_add = word\n",
        "\n",
        "                    if word == \"<DELETED>\":\n",
        "                        continue\n",
        "\n",
        "                    if word not in self.counts:\n",
        "                        word_to_add = \"<UNKNOWN>\"\n",
        "\n",
        "                    for j in range(-window, window+1):\n",
        "                        pos = i + j\n",
        "                        if pos >= 0 and pos < len(ns) and pos != i and ns[pos] != \"<DELETED>\":\n",
        "                            self.token_pairs.append((word_to_add, ns[pos]))\n",
        "\n",
        "        self.voc = np.array(list(self.counts.keys()))\n",
        "        self.token2id = dict([(token, i) for i, token in enumerate(self.voc)])\n",
        "        self.lc = len(self.voc)\n",
        "        den = 0\n",
        "        for word in self.counts:\n",
        "            den += pow(self.counts[word], 0.75)\n",
        "\n",
        "        self.prob = [pow(self.counts[word], 0.75) / den for word in self.voc]\n",
        "                    \n",
        "    def negative_sampling(self):\n",
        "        ind = np.random.choice(np.arange(self.lc), p=self.prob, size=self.neg_samp)\n",
        "        return list(ind)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        ns = self.negative_sampling();\n",
        "        t, c = self.token_pairs[index]\n",
        "\n",
        "        t = self.token2id[t]\n",
        "        c = self.token2id[c]\n",
        "        \n",
        "\n",
        "        return torch.tensor([t]), torch.tensor([c] + ns, dtype=torch.long)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_pairs)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVTSbVNxtfHm",
        "colab_type": "text"
      },
      "source": [
        "### Задание 2 (4 балла)\n",
        "Теперь реализуем непосредственно SkipGram. Для этого нам потребуются `torch.autograd.Variables` чтобы сделать эмбеддинги обучаемыми. Также сразу реализуем интерфейс, которым будем пользоваться для применения эмбеддингов в следующих задачах.\n",
        "\n",
        "#### Методы SkipGram\n",
        "`__init__` - принимает на вход словарь и размерность пространств эмбеддингов. Инициализирует эмбеддинги для центрального и контекстного слов.\n",
        "\n",
        "`get_variables` - возвращает лист из всех `torch.autograd.Variables`. Необходимо, чтобы инициализировать оптимизатор.\n",
        "\n",
        "`predict_proba(center_tokens, context_tokens)` - принимает на вход список центральных токенов и список списков токенов из предполагаемого контекста. Для каждого центрального токена и соответствующего ему списка контекстных токенов должен вернуть скалярное произведение центрального и контекстуального эмбеддингов.\n",
        "\n",
        "#### Методы Embedding\n",
        "`__init__` - принимает на вход обученный SkipGram\n",
        "\n",
        "`embed` - возвращает эмбеддинги для всех элементов списка\n",
        "\n",
        "`reconstruct` - для всех элементов списка возвращает наиболее подходящий токен. Не возвращает `\"<UNKNOWN>\"`\n",
        "\n",
        "`n_closest` - возвращает `n` ближайших токенов для каждого элемента списка. Не возвращает `\"<UNKNOWN>\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmG2UP2lKeLH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH6KjufRtfHo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SkipGram:\n",
        "    def __init__(self, voc, latent_size):\n",
        "        self.id2token = list(voc)\n",
        "        self.token2id = dict([(token, i) for i, token in enumerate(self.id2token)])\n",
        "        self.v = Variable(torch.randn(len(voc) ,latent_size).float().cuda(), requires_grad=True)\n",
        "        self.u = Variable(torch.randn(latent_size, len(voc)).float().cuda(), requires_grad=True)\n",
        "        self.ls = latent_size\n",
        "        \n",
        "    def get_variables(self):\n",
        "        return [self.v, self.u]\n",
        "    \n",
        "    def predict_proba(self, center_ids, context_ids):\n",
        "        bs = context_ids.shape[0]\n",
        "        ns = context_ids.shape[1]  \n",
        "        ls = self.ls\n",
        "        res = torch.bmm(self.v[center_ids], self.u[:,context_ids].transpose(1, 0))\n",
        "        return res.reshape(bs, ns).cuda()\n",
        "            \n",
        "class Embedding:\n",
        "    def __init__(self, skip_gram):\n",
        "        self.skip_gram = skip_gram\n",
        "        self.tree = KDTree(skip_gram.v.detach().numpy())\n",
        "    \n",
        "    def embed(self, tokens):\n",
        "        res = torch.zeros(len(tokens) , self.skip_gram.ls)\n",
        "        for i, token in enumerate(tokens):\n",
        "            if token in self.skip_gram.token2id:\n",
        "                res[i] = self.skip_gram.v[self.skip_gram.token2id[token]]\n",
        "            else:\n",
        "                res[i] = self.skip_gram.v[self.skip_gram.token2id[\"<UNKNOWN>\"]]\n",
        "        return res.detach().numpy()\n",
        "    \n",
        "    def reconstruct(self, embeddings):\n",
        "        _, inds = self.tree.query(embeddings, 2)\n",
        "        res = []\n",
        "        for ind in inds:\n",
        "            if not self.skip_gram.id2token[ind[0]] == \"<UNKNOWN>\":\n",
        "                res.append(self.skip_gram.id2token[ind[0]])\n",
        "            else:\n",
        "                res.append(self.skip_gram.id2token[ind[1]])\n",
        "        return res\n",
        "\n",
        "    def n_closest(self, embeddings, n=5):\n",
        "        res = [[] for _ in range(len(embeddings))]\n",
        "        _, inds = self.tree.query(embeddings, k=n+1)\n",
        "        for i, _ in enumerate(embeddings):\n",
        "            for ind in inds[i]:\n",
        "                if self.skip_gram.id2token[ind] != \"<UNKNOWN>\" and len(res[i]) < n:\n",
        "                    res[i].append(self.skip_gram.id2token[ind])\n",
        "        return res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTQV2DXrIJCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MyBatch:\n",
        "    def __init__(self, dataset, batch_size=4096, shuffle=False):\n",
        "        self.ds = dataset\n",
        "        self.bs = batch_size\n",
        "        self.sf = shuffle\n",
        "    \n",
        "    def batches(self):\n",
        "        bs = self.bs\n",
        "        ind = np.arange(len(self.ds))\n",
        "        if self.sf:\n",
        "            np.random.shuffle(ind)\n",
        "        res = []\n",
        "        for i in range(int(np.ceil(len(self.ds) / bs))):\n",
        "            if i % 100 == 99:\n",
        "                print(i)\n",
        "            cur = []\n",
        "            cur.append(torch.Tensor(ind[bs*i:(i+1)*bs]).reshape(bs, 1))\n",
        "            sec = None\n",
        "            for j in ind[bs*i:(i+1)*bs]:\n",
        "                if sec is None:\n",
        "                    sec = self.ds[j][1]\n",
        "                else:\n",
        "                    torch.cat((sec, self.ds[j][1]), 0)\n",
        "            cur.append(sec)\n",
        "            res.append(cur)\n",
        "        return res\n",
        "                \n",
        "        \n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FGgbcn8RGGZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = TokenDataset(tokenized, count_threshold=20, window=3, negative_sampling=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLO-WoXEtfHu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 4096\n",
        "EPOCHS = 5\n",
        "\n",
        "print(\"Creating dataset...\")\n",
        "dataset = TokenDataset(tokenized, count_threshold=20, window=3, negative_sampling=2)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "print(\"Creating skipgram...\")\n",
        "skipgram = SkipGram(dataset.voc, 12)\n",
        "optim = torch.optim.Adam(skipgram.get_variables(), lr=1e-3)\n",
        "y = torch.tensor([0] * (BATCH_SIZE + 1), dtype=torch.long).cuda()\n",
        "losses = []\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "    avg_loss = 0\n",
        "    steps = 0\n",
        "    ct = time.time()\n",
        "    for batch in tqdm(dataloader):\n",
        "        probs = skipgram.predict_proba(batch[0], batch[1])\n",
        "        loss = F.cross_entropy(probs, y[:len(probs)])\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        avg_loss += loss.item()\n",
        "        steps += 1\n",
        "        print(steps)\n",
        "    losses.append(avg_loss/steps)\n",
        "    print(\"Loss:\", avg_loss/steps)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(list(range(EPOCHS)), losses)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjCMDdPhIl7R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0c2f976d-7e4b-4bbb-8fb8-ce75557ae246"
      },
      "source": [
        "print(\"Creating dataset...\")\n",
        "dataset = TokenDataset(tokenized, count_threshold=20, window=3, negative_sampling=2)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating dataset...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBpMMZGaljoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ct = time.time()\n",
        "for batch in tqdm(dataloader):\n",
        "    print(time.time()-ct)\n",
        "    ct = time.time()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEck_1CptfHy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tt = t.batches()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B4fRZn-3tfH4",
        "colab_type": "code",
        "outputId": "d29c734a-f9f7-4bd7-f5be-8cb676a99f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "king = embedder.embed([\"король\"])[0]\n",
        "cat = embedder.embed([\"кошка\"])[0]\n",
        "owl = embedder.embed([\"сыч\"])[0]\n",
        "give = embedder.embed([\"дать\"])[0]\n",
        "me = embedder.embed([\"ты\"])[0]\n",
        "you = embedder.embed([\"я\"])[0]\n",
        "print(embedder.n_closest([king], 10)[0])\n",
        "print(embedder.n_closest([cat], 10)[0])\n",
        "print(embedder.n_closest([owl], 10)[0])\n",
        "print(embedder.n_closest([give], 10)[0])\n",
        "print(embedder.n_closest([me], 10)[0])\n",
        "print(embedder.n_closest([you], 10)[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['король', 'итогам', 'было', 'о', 'то', 'общества', 'направлено', 'известных', 'ну', 'также']\n",
            "['из', 'что', '-', '…', 'очень', 'которых', 'его', 'такой', 'ли', '10']\n",
            "['из', 'что', '-', '…', 'очень', 'которых', 'его', 'такой', 'ли', '10']\n",
            "['из', 'что', '-', '…', 'очень', 'которых', 'его', 'такой', 'ли', '10']\n",
            "['ты', ':', 'же', 'себе', 'за', 'ее', 'понятия', 'их', 'в', 'стране']\n",
            "['я', 'было', 'не', 'эти', 'по', 'от', 'всего', 'является', '–', 'могут']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx6WS7YjtfH6",
        "colab_type": "text"
      },
      "source": [
        "### Задание 3 (2 балла)\n",
        "Теперь будем учиться восстанавливать слова в тексте. Для этого нам потребуется также определить датасет последовательностей фиксированной длинны.\n",
        "\n",
        "#### Методы\n",
        "`__init__` - принимает на вход `embedder` (обученный SkipGram) и список токенизированных последоватлеьностей `tokenized`.\n",
        "\n",
        "`__getitem__` - возвращает случайную закодированную при помощи SkipGram подпоследовательность длины `seq_len` одной из исходных последовательностей, сдвинутую на один токен подпоследовательность (т.е. следующие слова в тексте) и маску, которая отражает то, является ли токен неизвестным (`\"<UNKNOWN\"`).\n",
        "\n",
        "`__len__` - равна количеству последовательностей."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nWaRjBctfH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TokenSeqDataset(Dataset):\n",
        "    def __init__(self, embedder, tokenized, seq_len=32):\n",
        "        self.seq_len = seq_len\n",
        "        self.tokenized = tokenized\n",
        "        self.embedder = embedder\n",
        "            \n",
        "    def __len__(self):\n",
        "        return len(tokenized)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        top = max(len(self.tokenized[index]) - self.seq_len, 0)\n",
        "            \n",
        "        ind = np.random.randint(0, 1 + top)\n",
        "        \n",
        "        sent = copy.deepcopy(self.tokenized[index])\n",
        "        sent = sent + [\"<END>\"] * (1 + max(0, self.seq_len-len(sent)))\n",
        "        seq = sent[ind: ind + self.seq_len + 1]\n",
        "        mask = [token in self.embedder.skip_gram.token2id\n",
        "                for token in seq[1:]]\n",
        "        mask = torch.Tensor(np.array(mask))\n",
        "        resseq = [self.embedder.embed([word])[0] for word in seq]\n",
        "        resseq = torch.Tensor(np.array(resseq))\n",
        "        a1 = copy.deepcopy(resseq[:-1])\n",
        "        a2 = copy.deepcopy(resseq[1:])\n",
        "        return a1, a2, mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVcblSvOtfH9",
        "colab_type": "text"
      },
      "source": [
        "### Задание 4 (2 балла)\n",
        "Теперь обучим рекуррентную сеть, которая будет предсказывать следующее слово в тексте. Модель будет состоять из трех блоков: `input` (отвечает за предоброботку эмбеддинга), `rnn` (рекуррентная часть), `output` (отвечает за постобработку выхода).\n",
        "\n",
        "#### Методы\n",
        "`predict_sequential` - возвращает последовательность предсказаний для батча последовательностей\n",
        "\n",
        "`get_next` - предсказывает следующее слово\n",
        "\n",
        "`reset` - обнуляет внутреннее состояние сети"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-Bm86KstfH-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextRNN:\n",
        "    def __init__(self, latent_space=150, hidden_layer=512):\n",
        "        self.input = torch.nn.Sequential(\n",
        "            torch.nn.Linear(latent_space, hidden_layer),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_layer, hidden_layer),\n",
        "            torch.nn.ReLU()\n",
        "        )\n",
        "        self.rnn = torch.nn.LSTM(hidden_layer, hidden_layer)\n",
        "        self.output = torch.nn.Linear(hidden_layer, latent_space)\n",
        "        self.input.cuda()\n",
        "        self.rnn.cuda()\n",
        "        self.output.cuda()\n",
        "        self.hidden = None\n",
        "    \n",
        "    def predict_sequential(self, sequences):\n",
        "        x, _ = self.rnn(self.input(sequences))\n",
        "        return self.output(x)\n",
        "    \n",
        "    def parameters(self):\n",
        "        return list(self.input.parameters()) + list(self.rnn.parameters()) + list(self.output.parameters())\n",
        "    \n",
        "    def get_next(self, batch):\n",
        "        x, self.hidden = self.rnn(self.input(sequences).unsqueeze(1))\n",
        "        return self.output(x)\n",
        "    \n",
        "    def reset(self):\n",
        "        self.hidden = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bP_H6NjPtfIJ",
        "colab_type": "code",
        "outputId": "b7d2aff2-1365-4d26-9476-e7afbf54b746",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783,
          "referenced_widgets": [
            "6bb1eb39337f4bcb8273c9f216478779",
            "fce62924c8ea4dd8a123465997f405fc",
            "60d686902fbe48faa4847c9667df3f56",
            "ce886172b417486b85341dd11bd857e1",
            "941f201d8b87486199295fed5f115a0b",
            "f6ef33a474024f79b4c7b8c0f4ea50e5",
            "39ad97bdc53d4406a7af801f33d11869",
            "d8762bc4271c47b08fc499e4d47aaa53",
            "cf713dcfb8774e5b86f000c36412b0cc"
          ]
        }
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 200\n",
        "\n",
        "dataset = TokenSeqDataset(embedder, tokenized)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "rnn = TextRNN(24)\n",
        "optim = torch.optim.Adam(rnn.parameters(), lr=1e-3)\n",
        "losses = []\n",
        "top1accs = []\n",
        "top5accs = []\n",
        "for i in range(EPOCHS):\n",
        "    avg_loss = 0\n",
        "    top1acc = 0\n",
        "    top5acc = 0\n",
        "    steps = 0\n",
        "    acc_steps = 0\n",
        "    for x, y_true, loss_mask in tqdm(dataloader):\n",
        "        y_pred = rnn.predict_sequential(x.cuda())\n",
        "        loss = (((y_true.cuda() - y_pred)**2).mean(dim=-1) * loss_mask.cuda()).mean()\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        avg_loss += loss.item()\n",
        "        steps += 1\n",
        "        if steps % 100 == 0:\n",
        "            acc_steps += 1\n",
        "            word_pred = embedder.n_closest(y_pred.detach().view(-1, 24)[:200].cpu().numpy())\n",
        "            word_true = embedder.reconstruct(y_true.detach().view(-1, 24)[:200].cpu().numpy())\n",
        "\n",
        "            unknown_mask = loss_mask.view(-1).cpu().numpy()\n",
        "            t1a = 0\n",
        "            t5a = 0\n",
        "            for true, pred, is_unknown in zip(word_true, word_pred, unknown_mask):\n",
        "                if is_unknown:\n",
        "                    continue\n",
        "                if true == pred[0]:\n",
        "                    t1a += 1\n",
        "                if true in pred:\n",
        "                    t5a += 1\n",
        "            top1acc += t1a / len(word_pred)\n",
        "            top5acc += t5a / len(word_pred)\n",
        "    losses.append(avg_loss/steps)\n",
        "    top1accs.append(top1acc/acc_steps)\n",
        "    top5accs.append(top5acc/acc_steps)\n",
        "    print(\"Loss:\", avg_loss/steps)\n",
        "    print(\"Top-1 accuracy:\", top1acc/acc_steps)\n",
        "    print(\"Top-5 accuracy:\", top5acc/acc_steps)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(list(range(EPOCHS)), losses)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "plt.figure(figsize=(12, 8))\n",
        "plt.plot(list(range(100)), top1accs, label=\"Top-1\")\n",
        "plt.plot(list(range(100)), top5accs, label=\"Top-5\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6bb1eb39337f4bcb8273c9f216478779",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.09322435809825345\n",
            "Top-1 accuracy: 0.0008333333333333334\n",
            "Top-5 accuracy: 0.07916666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fce62924c8ea4dd8a123465997f405fc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.08952413314947258\n",
            "Top-1 accuracy: 0.0008333333333333334\n",
            "Top-5 accuracy: 0.012499999999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60d686902fbe48faa4847c9667df3f56",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.08874099743722681\n",
            "Top-1 accuracy: 0.0008333333333333334\n",
            "Top-5 accuracy: 0.016666666666666666\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce886172b417486b85341dd11bd857e1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.08851615568480618\n",
            "Top-1 accuracy: 0.0016666666666666668\n",
            "Top-5 accuracy: 0.010833333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "941f201d8b87486199295fed5f115a0b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.08833593239023836\n",
            "Top-1 accuracy: 0.0008333333333333334\n",
            "Top-5 accuracy: 0.012499999999999999\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6ef33a474024f79b4c7b8c0f4ea50e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.08838290732935615\n",
            "Top-1 accuracy: 0.0025\n",
            "Top-5 accuracy: 0.013333333333333334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "39ad97bdc53d4406a7af801f33d11869",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.0879429124567992\n",
            "Top-1 accuracy: 0.0008333333333333334\n",
            "Top-5 accuracy: 0.015000000000000001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8762bc4271c47b08fc499e4d47aaa53",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loss: 0.08807886863418196\n",
            "Top-1 accuracy: 0.0008333333333333334\n",
            "Top-5 accuracy: 0.012500000000000002\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf713dcfb8774e5b86f000c36412b0cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=602), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-914faa8267ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0macc_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_mask\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_sequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm_notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tqdm/_tqdm.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    977\u001b[0m \"\"\", fp_write=getattr(self.fp, 'write', sys.stderr.write))\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-36cee17ae564>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 for token in seq[:-1]]\n\u001b[1;32m     20\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mresseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mresseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-36cee17ae564>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 for token in seq[:-1]]\n\u001b[1;32m     20\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mresseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mresseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresseq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-4530c8a1c6ff>\u001b[0m in \u001b[0;36membed\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_gram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_gram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                 \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_gram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_gram\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken2id\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"<UNKNOWN>\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5k4BxyutfIO",
        "colab_type": "text"
      },
      "source": [
        "### Задание 5 (1 балл)\n",
        "Отлично, осталось только научитсья итеративно продолжать последовательность. Давайте попробуем научиться это делать.\n",
        "\n",
        "#### Методы\n",
        "`continue_sequence` - возвращает завершенную последовательность. Входная последовательность может быть пустой, поэтому в начало нужно добавить токен `\"<START>\"`. Закончить построение последовательности нужно после получения токена `\"<END>\"` или после получения `max_len` новых слов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eUVmH_BtfIP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SequenceCompleter:\n",
        "    def __init__(self, rnn, embedder, max_len=128):\n",
        "        self.rnn = rnn\n",
        "        self.embedder = embeder\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def continue_sequence(self, sequence):\n",
        "        t_sequence = [\"<START>\"] + sequence\n",
        "        embedding = self.embedder.embed(t_sequence)\n",
        "        self.rnn.reset()\n",
        "        with torch.no_grad():\n",
        "            for e in embedding:\n",
        "                x = self.rnn.get_next(torch.tensor([e], dtype=torch.float).cuda())\n",
        "            rec = self.embeder.reconstruct(x)\n",
        "            continued_sequence = []\n",
        "            ctn = 0\n",
        "            while rec[0] != \"<END>\" and ctn < self.max_len:\n",
        "                continued_sequence.append(rec[0])\n",
        "                e = self.embedder.embed(rec)\n",
        "                x = self.rnn.get_next(torch.tensor(e, dtype=torch.float).cuda())\n",
        "                rec = self.embeder.reconstruct(x)\n",
        "        return sequence + continued_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyKf0z9etfIQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seq_completer = SequenceCompleter(rnn, embedder)\n",
        "print(seq_completer.continue_sequence([\"учеба\", \"в\", \"магистратуре\", \"-\", \"это\"]))\n",
        "print(seq_completer.continue_sequence([\"работает\", \"ли\", \"наша\", \"простая\", \"модель\", \"?\"]))\n",
        "print(seq_completer.continue_sequence([\"я\", \"точно\", \"знаю\"]))\n",
        "print(seq_completer.continue_sequence([\"машина\", \"времени\"]))\n",
        "print(seq_completer.continue_sequence([\"сегодня\"]))\n",
        "print(seq_completer.continue_sequence([]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICPLxaAZtfIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CharLSTM:\n",
        "    def __init__(self, symbols):\n",
        "        self.hidden = None\n",
        "        self.input = torch.nn.Linear(len(symbols), 128)\n",
        "        self.lstm = torch.nn.LSTM(128, 128)\n",
        "        self.output = torch.nn.Sequential(torch.nn.Linear(128, 128), torch.nn.ReLU(), torch.nn.Linear(128, len(symbols)))\n",
        "    \n",
        "    def loss(self, batch):\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}