{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WyncTKTlvfdw"
   },
   "source": [
    "# Нейронные сети\n",
    "__Суммарное количество баллов: 10__\n",
    "\n",
    "__Решение отправлять на `ml.course.practice@gmail.com`__\n",
    "\n",
    "__Тема письма: `[ML][HW06] <ФИ>`, где вместо `<ФИ>` указаны фамилия и имя__\n",
    "\n",
    "Для начала вам предстоит реализовать свой собственный backpropagation и протестировать его на реальных данных, а затем научиться обучать нейронные сети при помощи библиотеки `PyTorch` и использовать это умение для классификации классического набора данных CIFAR10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-2jd2bwkvfdy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "from sklearn.datasets import make_blobs, make_moons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-36kkGgDvfd2"
   },
   "source": [
    "### Задание 1 (3 балла)\n",
    "Нейронные сети состоят из слоев, поэтому для начала понадобится реализовать их. Пока нам понадобятся только три:\n",
    "\n",
    "`Linear` - полносвязный слой, в котором `y = Wx + b`, где `y` - выход, `x` - вход, `W` - матрица весов, а `b` - смещение. \n",
    "\n",
    "`ReLU` - слой, соответствующий функции активации `y = max(0, x)`.\n",
    "\n",
    "`Softmax` - слой, соответствующий функции активации [softmax](https://ru.wikipedia.org/wiki/Softmax)\n",
    "\n",
    "\n",
    "#### Методы\n",
    "`forward(X)` - возвращает предсказанные для `X`. `X` может быть как вектором, так и батчем\n",
    "\n",
    "`backward(d)` - считает градиент при помощи обратного распространения ошибки. Возвращает новое значение `d`\n",
    "\n",
    "`update(alpha)` - обновляет веса (если необходимо) с заданой скоростью обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fDO5Hg-uvfd3"
   },
   "outputs": [],
   "source": [
    "class Module:\n",
    "    def forward(self, x):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def backward(self, d):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def update(self, alpha):\n",
    "        pass\n",
    "        \n",
    "class Linear(Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.in_f = in_features\n",
    "        self.out_f = out_features\n",
    "        self.W = np.random.rand(self.in_f, self.out_f) * 0.01\n",
    "        self.b = np.zeros(self.out_f)\n",
    "        self.x = None\n",
    "        self.dw = None\n",
    "        self.db = None\n",
    "    \n",
    "    def forward(self, x): \n",
    "        self.x = np.copy(x)\n",
    "        if len(self.x.shape) == 1:\n",
    "            self.x.reshape(1, self.x.shape[0])\n",
    "        return np.dot(self.x, self.W) + self.b\n",
    "    \n",
    "    def backward(self, d):\n",
    "        self.dw = np.dot(self.x.T, d)\n",
    "        self.db = np.sum(d, axis = 0)\n",
    "#         self.d.reshape(1, self.d.shape[0])\n",
    "        return np.dot(d, self.W.T)\n",
    "        \n",
    "    def update(self, alpha):\n",
    "        self.W = self.W - alpha * self.dw\n",
    "        self.b = self.b - alpha * self.db\n",
    "        \n",
    "class ReLU(Module):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.x = np.copy(x)\n",
    "        if len(self.x.shape) == 1:\n",
    "            self.x.reshape(1, self.x.shape[0])\n",
    "        return np.maximum(self.x, 0)\n",
    "        \n",
    "    def backward(self, d):\n",
    "        ind = self.x > 0\n",
    "        return d * ind\n",
    "        \n",
    "class Softmax(Module):\n",
    "    def __init__(self):\n",
    "        self.x = None\n",
    "        self.p = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        self.x = np.copy(x)\n",
    "        if len(self.x.shape) == 1:\n",
    "            self.x.reshape(1, self.x.shape[0])\n",
    "        e = np.exp(self.x)\n",
    "        self.p = e / np.sum(e, axis = 1, keepdims = True)\n",
    "\n",
    "        return self.p\n",
    "        \n",
    "    def backward(self, y):\n",
    "        \n",
    "#         s = np.copy(self.x[np.arange(len(self.x)),y])\n",
    "\n",
    "#         s = - s + np.log(np.sum(np.exp(self.x),axis=-1))\n",
    "#         print(np.mean(s))\n",
    "        \n",
    "        d = np.copy(self.p)\n",
    "        d[np.arange(self.x.shape[0]), y] -= 1\n",
    "        return d / self.x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m47hhC2wvfd6"
   },
   "source": [
    "### Задание 2 (2 балла)\n",
    "Теперь сделаем саму нейронную сеть.\n",
    "\n",
    "#### Методы\n",
    "`fit(X, y)` - обучает нейронную сеть заданное число эпох. В каждой эпохе необходимо использовать [cross-entropy loss](https://ml-cheatsheet.readthedocs.io/en/latest/loss_functions.html#cross-entropy) для обучения, а так же производить обновления не по одному элементу, а используя батчи.\n",
    "\n",
    "`predict_proba(X)` - предсказывает вероятности классов для элементов `X`\n",
    "\n",
    "#### Параметры конструктора\n",
    "`modules` - список, состоящий из ранее реализованных модулей и описывающий слои нейронной сети. В конец необходимо добавить `Softmax`\n",
    "\n",
    "`epochs` - количество эпох обучения\n",
    "\n",
    "`alpha` - скорость обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ue1WMO_jvfd7"
   },
   "outputs": [],
   "source": [
    "class MLPClassifier:\n",
    "    def __init__(self, modules, epochs=100, alpha=0.01, batch_size = 100):\n",
    "        self.modules = modules + [Softmax()]\n",
    "        self.epochs = epochs\n",
    "        self.alpha = alpha\n",
    "        self.bs = batch_size\n",
    "    \n",
    "    \n",
    "    def forward(self, X):\n",
    "        cur = X\n",
    "        for module in self.modules:\n",
    "            cur = module.forward(cur)\n",
    "        return cur\n",
    "    \n",
    "    def backward(self, d):\n",
    "        cur = d\n",
    "        for i, module in enumerate(reversed(self.modules)):\n",
    "            cur = module.backward(cur)\n",
    "    \n",
    "    def update(self):\n",
    "        for module in self.modules:\n",
    "            if isinstance(module, Linear):\n",
    "                module.update(self.alpha)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        for _ in range(self.epochs):\n",
    "            bs = self.bs\n",
    "            for j in range((len(X)+bs-1) // bs):\n",
    "                cX = X[j*bs:j*bs+bs]\n",
    "                cy = y[j*bs:j*bs+bs]\n",
    "\n",
    "                self.forward(cX)\n",
    "                self.backward(cy)\n",
    "                self.update()\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        cur = X\n",
    "        for i in range(len(self.modules)):\n",
    "            cur = self.modules[i].forward(cur)\n",
    "        return cur\n",
    "        \n",
    "    def predict(self, X):\n",
    "        p = self.predict_proba(X)\n",
    "        return np.argmax(p, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5deJu5I6vfd9"
   },
   "outputs": [],
   "source": [
    "p = MLPClassifier([\n",
    "    Linear(4, 64),\n",
    "    ReLU(),\n",
    "    Linear(64, 64),\n",
    "    ReLU(),\n",
    "    Linear(64, 2)\n",
    "], 4000, 0.1)\n",
    "\n",
    "X = np.random.randn(50, 4)\n",
    "y = [(0 if x[0] > x[2]**2 or x[3]**3 > 0.5 else 1) for x in X]\n",
    "p.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2m1EAHrfvfd_"
   },
   "source": [
    "### Задание 3 (2 балла)\n",
    "Протестируем наше решение на синтетических данных. Необходимо подобрать гиперпараметры, при которых качество полученных классификаторов будет достаточным.\n",
    "\n",
    "#### Оценка\n",
    "Accuracy на первом датасете больше 0.85 - +1 балл\n",
    "\n",
    "Accuracy на втором датасете больше 0.85 - +1 балл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_zL1BhCHvfeA"
   },
   "outputs": [],
   "source": [
    "X, y = make_moons(400, noise=0.075)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "NZUCL0uEvfeC",
    "outputId": "12f6bf2d-3370-4531-d520-d16b0fb813b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.81365411,  0.64265519],\n",
       "       [ 0.23060704,  0.93915233],\n",
       "       [ 0.98279449,  0.03142884]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[[1,2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R3Zrs5JCvfeF",
    "outputId": "c69227e6-e520-47ac-b267-7c3a84c20d04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.8875\n"
     ]
    }
   ],
   "source": [
    "X, y = make_moons(400, noise=0.075)\n",
    "X_test, y_test = make_moons(400, noise=0.075)\n",
    "\n",
    "best_acc = 0\n",
    "for _ in range(1):\n",
    "    p = MLPClassifier([\n",
    "    Linear(2, 100),\n",
    "    ReLU(),\n",
    "    Linear(100, 27),\n",
    "    ReLU(),\n",
    "    Linear(27, 3)\n",
    "    ], 1000, 0.1)\n",
    "\n",
    "    p.fit(X, y)\n",
    "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
    "print(\"Accuracy\", best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OjZF6ypDvfeH",
    "outputId": "d5c677fd-c186-4aed-e918-a59f838e2c3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.94\n"
     ]
    }
   ],
   "source": [
    "X, y = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
    "X_test, y_test = make_blobs(400, 2, centers=[[0, 0], [2.5, 2.5], [-2.5, 3]])\n",
    "best_acc = 0\n",
    "for i in range(1):\n",
    "    p = MLPClassifier([\n",
    "    Linear(2, 100),\n",
    "    ReLU(),\n",
    "    Linear(100, 27),\n",
    "    ReLU(),\n",
    "    Linear(27, 3)\n",
    "    ], 1000, 0.1)\n",
    "\n",
    "\n",
    "    p.fit(X, y)\n",
    "    best_acc = max(np.mean(p.predict(X_test) == y_test), best_acc)\n",
    "print(\"Accuracy\", best_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ExLQ0W5vfeI"
   },
   "source": [
    "## PyTorch\n",
    "\n",
    "Для выполнения следующего задания понадобится PyTorch. [Инструкция по установке](https://pytorch.org/get-started/locally/)\n",
    "\n",
    "Если у вас нет GPU, то можно использовать [Google Colab](https://colab.research.google.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNi5x2tcvfeJ"
   },
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "tHUniMwovfeK",
    "outputId": "4bf56735-c635-4b62-af89-3a3d1237004f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "t = transforms.ToTensor()\n",
    "\n",
    "cifar_train = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=True, transform=t)\n",
    "train_loader = DataLoader(cifar_train, batch_size=1024, shuffle=True, pin_memory=torch.cuda.is_available())\n",
    "cifar_test = datasets.CIFAR10(\"datasets/cifar10\", download=True, train=False, transform=t)\n",
    "test_loader = DataLoader(cifar_test, batch_size=1024, shuffle=False, pin_memory=torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EtHd1ZazvfeN"
   },
   "source": [
    "### Задание 4 (3 балла)\n",
    "А теперь поработам с настоящими нейронными сетями и настоящими данными. Необходимо реализовать сверточную нейронную сеть, которая будет классифицировать изображения из датасета CIFAR10. Имплементируйте класс `Model` и функцию `calculate_loss`. \n",
    "\n",
    "Обратите внимание, что `Model` должна считать в конце `softmax`, т.к. мы решаем задачу классификации. Соответствеено, функция `calculate_loss` считает cross-entropy.\n",
    "\n",
    "Для успешного выполнения задания необходимо, чтобы `accuracy`, `mean precision` и `mean recall` были больше 0.5\n",
    "\n",
    "__Можно пользоваться всем содержимым библиотеки PyTorch.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GYRniL0yvfeN"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n1, n2):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList((nn.Linear(32*32*3, n1), nn.ReLU(),\n",
    "                       nn.Linear(n1, n2), nn.ReLU(),\n",
    "                       nn.Linear(n2, 10), nn.Softmax(dim=1)))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.reshape([x.shape[0], 32*32*3])\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "        \n",
    "def calculate_loss(X, y, model):\n",
    "\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    res = model.forward(X)\n",
    "    return loss(res, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WanUNbYIvfeO"
   },
   "source": [
    "Теперь обучим нашу модель. Для этого используем ранее созданные batch loader'ы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F5KHM6rFvfeP"
   },
   "outputs": [],
   "source": [
    "def train(model, epochs=100):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    for i in range(epochs):\n",
    "        #Train\n",
    "        loss_mean = 0\n",
    "        elements = 0\n",
    "        for X, y in iter(train_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = calculate_loss(X, y, model)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            loss_mean += loss.item() * len(X)\n",
    "            elements += len(X)\n",
    "        train_losses.append(loss_mean / elements)\n",
    "        #Test\n",
    "        loss_mean = 0 \n",
    "        elements = 0\n",
    "        for X, y in iter(test_loader):\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            loss = calculate_loss(X, y, model)\n",
    "            loss_mean += loss.item() * len(X)\n",
    "            elements += len(X)\n",
    "        test_losses.append(loss_mean / elements)\n",
    "        print(\"Epoch\", i, \"| Train loss\", train_losses[-1], \"| Test loss\", test_losses[-1])\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "poZZUsVFvfeQ",
    "outputId": "9012025d-a076-4e32-fee8-2dd4faf65154",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss 2.2168932166290283 | Test loss 2.1624284496307373\n",
      "Epoch 1 | Train loss 2.1386241943359376 | Test loss 2.126151993179321\n",
      "Epoch 2 | Train loss 2.117949223098755 | Test loss 2.107931119918823\n",
      "Epoch 3 | Train loss 2.0991981775665285 | Test loss 2.0983351211547854\n",
      "Epoch 4 | Train loss 2.090396619338989 | Test loss 2.089881625366211\n",
      "Epoch 5 | Train loss 2.0819976610565187 | Test loss 2.087142436981201\n",
      "Epoch 6 | Train loss 2.0735295722198486 | Test loss 2.075954607772827\n",
      "Epoch 7 | Train loss 2.06175860496521 | Test loss 2.075271621322632\n",
      "Epoch 8 | Train loss 2.0664703466796874 | Test loss 2.0616686195373535\n",
      "Epoch 9 | Train loss 2.05275888961792 | Test loss 2.0590393623352052\n",
      "Epoch 10 | Train loss 2.0440520961761472 | Test loss 2.0544930168151856\n",
      "Epoch 11 | Train loss 2.043223975067139 | Test loss 2.057649287414551\n",
      "Epoch 12 | Train loss 2.0350893293762207 | Test loss 2.0572253875732422\n",
      "Epoch 13 | Train loss 2.034312051010132 | Test loss 2.0454888683319092\n",
      "Epoch 14 | Train loss 2.0250141202545167 | Test loss 2.0484198066711428\n",
      "Epoch 15 | Train loss 2.0233173905944826 | Test loss 2.0404719219207763\n",
      "Epoch 16 | Train loss 2.0177697410583497 | Test loss 2.0327190452575685\n",
      "Epoch 17 | Train loss 2.0131128270339964 | Test loss 2.0192525943756103\n",
      "Epoch 18 | Train loss 1.989569090499878 | Test loss 2.008595404434204\n",
      "Epoch 19 | Train loss 1.9880268458557129 | Test loss 2.017135038757324\n",
      "Epoch 20 | Train loss 1.9859200824737548 | Test loss 1.9977981746673583\n",
      "Epoch 21 | Train loss 1.9788715701293946 | Test loss 2.0028641960144045\n",
      "Epoch 22 | Train loss 1.9739239545440674 | Test loss 2.0006951110839846\n",
      "Epoch 23 | Train loss 1.964027573699951 | Test loss 1.988428405380249\n",
      "Epoch 24 | Train loss 1.9634270914077758 | Test loss 1.9989122146606446\n",
      "Epoch 25 | Train loss 1.9631479681015014 | Test loss 1.9849421173095703\n",
      "Epoch 26 | Train loss 1.9567509172439574 | Test loss 1.9965079776763917\n",
      "Epoch 27 | Train loss 1.951807609024048 | Test loss 1.9890902633666991\n",
      "Epoch 28 | Train loss 1.947712719116211 | Test loss 1.9930447227478028\n",
      "Epoch 29 | Train loss 1.9461547821426393 | Test loss 1.9921307662963867\n",
      "Epoch 30 | Train loss 1.9405981495666504 | Test loss 1.9932446102142334\n",
      "Epoch 31 | Train loss 1.939739144668579 | Test loss 1.9792613861083985\n",
      "Epoch 32 | Train loss 1.9336094744873047 | Test loss 1.981465022277832\n",
      "Epoch 33 | Train loss 1.9339646435928344 | Test loss 1.9820605018615722\n",
      "Epoch 34 | Train loss 1.9313035620117187 | Test loss 1.9736612335205077\n",
      "Epoch 35 | Train loss 1.9218514965820312 | Test loss 1.9777623792648316\n",
      "Epoch 36 | Train loss 1.9214384994125366 | Test loss 1.9752211540222169\n",
      "Epoch 37 | Train loss 1.9196993845367432 | Test loss 1.976670791053772\n",
      "Epoch 38 | Train loss 1.9217680514907838 | Test loss 1.9703073524475099\n",
      "Epoch 39 | Train loss 1.9263100227737426 | Test loss 1.9720691255569458\n",
      "Epoch 40 | Train loss 1.9168377390670777 | Test loss 1.9793559467315673\n",
      "Epoch 41 | Train loss 1.9145423639678956 | Test loss 1.966465989112854\n",
      "Epoch 42 | Train loss 1.9055191316986084 | Test loss 1.9682157222747803\n",
      "Epoch 43 | Train loss 1.9022107320404054 | Test loss 1.9669372270584107\n",
      "Epoch 44 | Train loss 1.8961659102630615 | Test loss 1.9608540782928467\n",
      "Epoch 45 | Train loss 1.8962504681015016 | Test loss 1.964929391670227\n",
      "Epoch 46 | Train loss 1.898048006210327 | Test loss 1.9587755001068115\n",
      "Epoch 47 | Train loss 1.8983805670547484 | Test loss 1.9645753620147706\n",
      "Epoch 48 | Train loss 1.8914224948120117 | Test loss 1.9585133878707885\n",
      "Epoch 49 | Train loss 1.8829046271133423 | Test loss 1.965695175743103\n",
      "Epoch 50 | Train loss 1.8888389850997924 | Test loss 1.957650715637207\n",
      "Epoch 51 | Train loss 1.8863161086273192 | Test loss 1.9509754016876222\n",
      "Epoch 52 | Train loss 1.881566770362854 | Test loss 1.9638046157836915\n",
      "Epoch 53 | Train loss 1.8812962302398681 | Test loss 1.9494556875228881\n",
      "Epoch 54 | Train loss 1.8761127041625976 | Test loss 1.9621642721176147\n",
      "Epoch 55 | Train loss 1.8731185195159912 | Test loss 1.953408825492859\n",
      "Epoch 56 | Train loss 1.871572303199768 | Test loss 1.9491986894607545\n",
      "Epoch 57 | Train loss 1.8646590144729613 | Test loss 1.9474803565979004\n",
      "Epoch 58 | Train loss 1.8644491926574707 | Test loss 1.947694554710388\n",
      "Epoch 59 | Train loss 1.86542655128479 | Test loss 1.9554373920440673\n",
      "Epoch 60 | Train loss 1.8664548545074462 | Test loss 1.9592500076293946\n",
      "Epoch 61 | Train loss 1.85871030292511 | Test loss 1.9477493377685546\n",
      "Epoch 62 | Train loss 1.8565398892593383 | Test loss 1.9455288248062135\n",
      "Epoch 63 | Train loss 1.8552401612472533 | Test loss 1.95193297290802\n",
      "Epoch 64 | Train loss 1.8526736661529541 | Test loss 1.9481671855926515\n",
      "Epoch 65 | Train loss 1.8492338019180299 | Test loss 1.9456724338531495\n",
      "Epoch 66 | Train loss 1.845602467803955 | Test loss 1.9480638034820557\n",
      "Epoch 67 | Train loss 1.843479474182129 | Test loss 1.9474360754013063\n",
      "Epoch 68 | Train loss 1.8476012092590333 | Test loss 1.944116862487793\n",
      "Epoch 69 | Train loss 1.8442299857330322 | Test loss 1.9492391759872436\n",
      "Epoch 70 | Train loss 1.8440294731140137 | Test loss 1.9466993669509887\n",
      "Epoch 71 | Train loss 1.841934301071167 | Test loss 1.9439645725250243\n",
      "Epoch 72 | Train loss 1.8458288771438598 | Test loss 1.94023385181427\n",
      "Epoch 73 | Train loss 1.8353432221221924 | Test loss 1.9372056074142456\n",
      "Epoch 74 | Train loss 1.8283564751434327 | Test loss 1.9437258882522583\n",
      "Epoch 75 | Train loss 1.8317551662445068 | Test loss 1.949028537750244\n",
      "Epoch 76 | Train loss 1.8318462578201293 | Test loss 1.9452885459899902\n",
      "Epoch 77 | Train loss 1.8274309332275391 | Test loss 1.9454564712524414\n",
      "Epoch 78 | Train loss 1.828542605934143 | Test loss 1.9455793542861939\n",
      "Epoch 79 | Train loss 1.8260150847625733 | Test loss 1.9412497777938842\n",
      "Epoch 80 | Train loss 1.8285130828094482 | Test loss 1.9471303462982177\n",
      "Epoch 81 | Train loss 1.832834345817566 | Test loss 1.945668391418457\n",
      "Epoch 82 | Train loss 1.825917021331787 | Test loss 1.9350736915588378\n",
      "Epoch 83 | Train loss 1.8169971459197998 | Test loss 1.9433614624023436\n",
      "Epoch 84 | Train loss 1.8161746560287475 | Test loss 1.938910800743103\n",
      "Epoch 85 | Train loss 1.8112879697036743 | Test loss 1.9338845586776734\n",
      "Epoch 86 | Train loss 1.815073443107605 | Test loss 1.9448536262512206\n",
      "Epoch 87 | Train loss 1.8169342402648925 | Test loss 1.9405969615936278\n",
      "Epoch 88 | Train loss 1.8134862202072144 | Test loss 1.9434761360168458\n",
      "Epoch 89 | Train loss 1.8153131215667724 | Test loss 1.939477681541443\n",
      "Epoch 90 | Train loss 1.8094271711349488 | Test loss 1.9327696168899535\n",
      "Epoch 91 | Train loss 1.807613313102722 | Test loss 1.9408922706604004\n",
      "Epoch 92 | Train loss 1.8008467405700683 | Test loss 1.9324421865463257\n",
      "Epoch 93 | Train loss 1.7971179151535035 | Test loss 1.9370186382293701\n",
      "Epoch 94 | Train loss 1.8006918058013917 | Test loss 1.937524356651306\n",
      "Epoch 95 | Train loss 1.8024370415878297 | Test loss 1.9348574743270874\n",
      "Epoch 96 | Train loss 1.7949688161849975 | Test loss 1.9335773527145386\n",
      "Epoch 97 | Train loss 1.7960525994110108 | Test loss 1.9472249423980712\n",
      "Epoch 98 | Train loss 1.7936808989715576 | Test loss 1.9367897621154786\n",
      "Epoch 99 | Train loss 1.7963549431991577 | Test loss 1.937249403190613\n"
     ]
    }
   ],
   "source": [
    "model = Model(1000, 100).to(device)\n",
    "train_l, test_l = train(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eaJiJtElvfeR"
   },
   "source": [
    "Построим график функции потерь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "UxTtIuRIvfeR",
    "outputId": "1d2df55b-08d0-4bc2-86c5-0fe4e4e318a4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAGoCAYAAABbkkSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nERERCREFLBERERERkRD5/4TM4JxAm8eMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(len(train_l)), train_l, label=\"train\")\n",
    "plt.plot(range(len(test_l)), test_l, label=\"test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MSzSqJSfvfeT"
   },
   "source": [
    "И, наконец, посчитаем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "PLPYQPCPvfeT",
    "outputId": "bcfe2054-964f-4ae9-c488-31bc0ec7d082"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy 0.5203\n",
      "Precision [0.54655172 0.61724806 0.40737327 0.33743274 0.50307503 0.43391188\n",
      " 0.6519945  0.59818731 0.60821918 0.55789474]\n",
      "Recall [0.634 0.637 0.442 0.439 0.409 0.325 0.474 0.594 0.666 0.583]\n",
      "Mean Precision 0.5261888439385471\n",
      "Mean Recall 0.5203\n"
     ]
    }
   ],
   "source": [
    "true_positive = np.zeros(10)\n",
    "true_negative = np.zeros(10)\n",
    "false_positive = np.zeros(10)\n",
    "false_negative = np.zeros(10)\n",
    "accuracy = 0\n",
    "ctn = 0\n",
    "for X, y in iter(test_loader):\n",
    "    X = X.to(device)\n",
    "    y = y.to(device)\n",
    "    with torch.no_grad():\n",
    "        y_pred = model(X).max(dim=1)[1]\n",
    "    for i in range(10):\n",
    "        for pred, real in zip(y_pred, y):\n",
    "            if real == i:\n",
    "                if pred == real:\n",
    "                    true_positive[i] += 1\n",
    "                else:\n",
    "                    false_negative[i] += 1\n",
    "            else:\n",
    "                if pred == i:\n",
    "                    false_positive[i] += 1\n",
    "                else:\n",
    "                    true_negative[i] += 1\n",
    "            \n",
    "    accuracy += torch.sum(y_pred == y).item()\n",
    "    ctn += len(y)\n",
    "print(\"Overall accuracy\", accuracy / ctn)\n",
    "print(\"Precision\", true_positive / (true_positive + false_positive))\n",
    "print(\"Recall\", true_positive / (true_positive + false_negative))\n",
    "print(\"Mean Precision\", np.mean(true_positive / (true_positive + false_positive)))\n",
    "print(\"Mean Recall\", np.mean(true_positive / (true_positive + false_negative)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oJlnB1xZvfeU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw05_task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
